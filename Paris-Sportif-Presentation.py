#importation de toutes les librairies

import pandas as pd
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import seaborn as sns
import joblib
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn import tree
from sklearn.neighbors import KNeighborsClassifier  # Import de k-NN
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

#lecture du csv atp ,son affichage et les diff√©rentes informations du jeux 

#atp=pd.read_csv('atp_data.csv')
#st.dataframe(atp.head())

#Cr√©ation des pages

st.title("Projet de classification binaire Paris Sportif")
st.sidebar.title("Sommaire")


pages = [
    "Contexte du projet",
    "Le Jeu De Donn√©es",
    "Quelques visualisations",
    "Pr√©paration des donn√©es",
    "Mod√©lisation",
    "Application m√©tier et conclusion",
    " Perspectives"
]

page = st.sidebar.radio("Aller vers la page", pages)

# Liste des auteurs dans la sidebar (avec markdown pour liste √† puces)
st.sidebar.markdown("### Auteurs")
st.sidebar.markdown("""
- Nafissatou K.
- [Nom Auteur 2]
- [Nom Auteur 3]
""")


#######Page 0
if page == pages[0]:
    st.write("### Contexte du projet")
    st.markdown("""
Ce projet a √©t√© r√©alis√© dans le cadre de notre formation en data science via l'organisme [Datascientest](https://datascientest.com).  
L'objectif est de pr√©dire l'issue de matchs de tennis, √† partir du jeu de donn√©es disponible sur [Kaggle](https://www.kaggle.com/datasets/edouardthomas/atp-matches-dataset).

Ce Streamlit pr√©sente notre d√©marche pour mener √† bien ce projet, depuis l'exploration des donn√©es jusqu'√† la cr√©ation des variables explicatives.  
Les meilleurs r√©sultats que nous avons pu obtenir y seront pr√©sent√©s, avec la partie Machine Learning qui vous permettra de tester vous-m√™me les variables que nous avons cr√©√©es sur diff√©rents algorithmes.
""")


    st.image("/Users/nafissatoukm/Desktop/Streamlit/cas2/tennis-paris-sportifs.jpg", use_column_width=True)


#######Page 1
if page == pages[1]:
    st.write("### 5 premi√®re lignes du Jeu de Donn√©es")
    atp = pd.read_csv('atp_data.csv')
    st.dataframe(atp.head())
    
    st.write("### Dimensions du Jeu De Donn√©es")
    st.dataframe(atp.shape)
    
    st.write("### Pr√©sence de Doublons")
    if st.checkbox("Afficher les doublons"):
        st.write("### Doublons dans le dataset ATP")
        doublons = atp[atp.duplicated()]
        if doublons.empty:
            st.write("Aucun doublon trouv√©.")
        else:
            st.dataframe(doublons)

    st.write("### Le Jeu De Donn√©es")
    st.markdown("""
Ce projet s‚Äôappuie sur un jeu de donn√©es issu des comp√©titions ATP (Association of Tennis Professionals), 
couvrant un grand nombre de matchs professionnels de tennis. L‚Äôobjectif est de pr√©dire,
√† partir de ces donn√©es historiques, la probabilit√© qu‚Äôun joueur A batte un joueur B ‚Äî 
et ainsi tenter de faire mieux que les mod√®les pr√©dictifs des bookmakers.
""")
    st.markdown("""
Voici une description d√©taill√©e des variables du dataset ATP et du deuxi√®me csv confidence disponible sur [Kaggle](https://www.kaggle.com/datasets/edouardthomas/atp-matches-dataset).
""")

    # Donn√©es descriptives par variable
    data = {
        "N¬∞": list(range(1, 24)),
        "Nom de la colonne": [
            "ATP", "Location", "Tournament", "Date", "Series", "Court", "Surface", "Round",
            "Best of", "Winner", "Loser", "WRank", "LRank", "Wsets", "Lsets", "Comment",
            "PSW", "PSL", "B365W", "B365L", "elo_winner", "elo_loser", "proba_elo"
        ],
        "Description": [
            "Identifiant du tournoi",
            "Lieu du match (ville ou pays)",
            "Nom du tournoi (correspondance avec ATP)",
            "Date du match (√† convertir en datetime)",
            "S√©rie du tournoi (niveau: Grand Slam, ATP 1000, etc.)",
            "Type de court (Indoor/Outdoor)",
            "Surface du match (Hard, Clay, Grass, Carpet)",
            "Tour du tournoi",
            "Format du match (meilleur de 3 ou 5 sets)",
            "Nom du joueur gagnant",
            "Nom du joueur perdant",
            "Classement mondial joueur gagnant",
            "Classement mondial joueur perdant",
            "Sets gagn√©s par joueur gagnant",
            "Sets gagn√©s par joueur perdant",
            "Issue du match (Completed, Retired, Walkover, Disqualified)",
            "Probabilit√© victoire joueur gagnant (mod√®les pr√©dictifs)",
            "Probabilit√© victoire joueur perdant (mod√®les pr√©dictifs)",
            "Cote bookmaker joueur gagnant (Bet365)",
            "Cote bookmaker joueur perdant (Bet365)",
            "Score Elo joueur gagnant",
            "Score Elo joueur perdant",
            "Probabilit√© victoire joueur gagnant (Elo)"
        ],
        "Disponible en pr√©diction": [
            "Oui", "Oui", "Oui", "Oui", "Oui", "Oui", "Oui", "Oui", "Oui",
            "Non", "Non", "Oui", "Oui", "Non", "Non", "Non", "Oui", "Oui",
            "Oui", "Oui", "Oui", "Oui", "Oui"
        ],
        "Type informatique": [
            "int64", "object", "object", "object", "object", "object", "object",
            "object", "int64", "object", "object", "int64", "int64", "float64",
            "float64", "object", "float64", "float64", "float64", "float64",
            "float64", "float64", "float64"
        ],
        "Taux de NA (%)": [
            "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0",
            "41.8", "41.8", "0", "26.8", "26.8", "12.7", "12.6", "0", "0", "0"
        ],
        "Gestion des NA": [
            "‚Äî", "‚Äî", "‚Äî", "‚Äî", "‚Äî", "‚Äî", "‚Äî", "‚Äî", "‚Äî",
            "‚Äî", "‚Äî", "‚Äî", "‚Äî", "Suppression ou moyenne", "Suppression ou moyenne", "‚Äî",
            "Remplacement par m√©diane", "Remplacement par m√©diane", "Remplacement par moyenne",
            "Remplacement par moyenne", "‚Äî", "‚Äî", "‚Äî"
        ],
        "Commentaires / Distribution": [
            "Quantitative, pas de NA",
            "Cat√©gorielle (>10 cat√©gories), pas de NA",
            "Cat√©gorielle (>10 cat√©gories), pas de NA",
            "Date √† convertir au format datetime",
            "Cat√©gorielle, 8 cat√©gories: International, Grand Slam, etc.",
            "Cat√©gorielle, 2 cat√©gories: Indoor, Outdoor",
            "Cat√©gorielle, 4 cat√©gories: Hard, Clay, Grass, Carpet",
            "Cat√©gorielle, 8 cat√©gories (tours du tournoi)",
            "Quantitative, pas de NA",
            "Cat√©gorielle, non disponible avant match",
            "Cat√©gorielle, non disponible avant match",
            "Quantitative, pas de NA",
            "Quantitative, pas de NA",
            "Quantitative, NA ~42%, convertir float -> int",
            "Quantitative, NA ~42%, convertir float -> int",
            "Cat√©gorielle, 4 modalit√©s: Completed, Retired, Walkover, Disqualified",
            "Quantitative, NA > 20%, remplacer par m√©diane",
            "Quantitative, NA > 20%, remplacer par m√©diane",
            "Quantitative, NA ~13%, remplacer par moyenne",
            "Quantitative, NA ~13%, remplacer par moyenne",
            "Quantitative, pas de NA",
            "Quantitative, pas de NA",
            "Quantitative, pas de NA"
        ]
    }

    df = pd.DataFrame(data)

    st.subheader("Description d√©taill√©e des variables ATP")
    st.table(df)

    st.markdown("""
---
### Informations suppl√©mentaires du deuxi√®me dataset confidence

| N¬∞ | Col           | Description                               | Disponibilit√© de la variable a priori | Type informatique | Taux de NA | Gestion des NA                     | Distribution des valeurs | Remarques sur la colonne                                         |
|----|---------------|-----------------------------------------|-------------------------------------|-------------------|------------|-----------------------------------|-------------------------|-----------------------------------------------------------------|
| 1  | match         | Identifiant ou description du match     | oui                                 | int64             | 0.00000    | ‚Äî                                 | Quantitative            |                                                                 |
| 2  | PSW           | Probabilit√© de victoire du joueur gagnant | oui                                 | float64           | 0.416139   | <5% supprimer ou remplacer par la moyenne | Quantitative            | Peut √™tre utilis√©e pour fusion mais induit des erreurs au niveau des dates |
| 3  | win0          | 1 = victoire, 0 = d√©faite                | oui                                 | int64             | 0.00000    | ‚Äî                                 | Quantitative            | Potentielle variable cible                                       |
| 4  | confidence0   | Confiance du mod√®le dans la pr√©diction  | oui                                 | float64           | 0.00000    | ‚Äî                                 | Quantitative            |                                                                 |
| 5  | date          | Date √† laquelle le match a eu lieu       | oui                                 | object            | 0.00000    | ‚Äî                                 | ‚Äî                       | √Ä convertir en datetime                                          |

---

""")

    st.markdown("""
La fusion avec des deux datasets a √©t√© envisag√©e puis abondonn√©e car complexe et g√©n√©re des NA importants.
""")

#######Page 2
# Charger les donn√©es une seule fois et les cacher pour optimiser
@st.cache_data
def load_data():
    return pd.read_csv('atp_data.csv')

atp = load_data()

if page == pages[2]:
    st.write("### Quelques visualisations")
    fig = px.scatter(
        atp,
        x='B365W',
        y='PSW',
        title='Comparaison entre B365W et PSW en fonction des athl√®tes gagnants',
        labels={'B365W': 'Cote Bookmaker B365W', 'PSW': 'Probabilit√© Mod√®le PSW'},
        color='Winner'
    )
    st.plotly_chart(fig, use_container_width=True)

#######Page 3
# Fonction de cr√©ation de la cible
def create_target_with_random_inversion(data, seed=None):
    expected_cols = ['Winner', 'Loser', 'WRank', 'LRank', 'Wsets', 'Lsets', 'elo_winner', 'elo_loser']
    missing_cols = [col for col in expected_cols if col not in data.columns]
    if missing_cols:
        raise ValueError(f"Colonnes manquantes : {missing_cols}")
    
    if seed is not None:
        np.random.seed(seed)

    targets = []
    inversions = np.random.rand(len(data)) < 0.5

    for i in range(len(data)):
        row = data.iloc[i]
        if inversions[i]:
            data.at[i, 'PlayerA'] = row['Loser']
            data.at[i, 'PlayerB'] = row['Winner']
            data.at[i, 'RankA'] = row['LRank']
            data.at[i, 'RankB'] = row['WRank']
            data.at[i, 'SetsA'] = row['Lsets']
            data.at[i, 'SetsB'] = row['Wsets']
            data.at[i, 'EloA'] = row['elo_loser']
            data.at[i, 'EloB'] = row['elo_winner']
            targets.append(0)
        else:
            data.at[i, 'PlayerA'] = row['Winner']
            data.at[i, 'PlayerB'] = row['Loser']
            data.at[i, 'RankA'] = row['WRank']
            data.at[i, 'RankB'] = row['LRank']
            data.at[i, 'SetsA'] = row['Wsets']
            data.at[i, 'SetsB'] = row['Lsets']
            data.at[i, 'EloA'] = row['elo_winner']
            data.at[i, 'EloB'] = row['elo_loser']
            targets.append(1)
    data['Target'] = targets

# Page 3 - Pr√©paration des donn√©es
if page == pages[3]:
    st.title("üßº Pr√©paration des donn√©es")

    st.markdown("""
## Objectif :
Nettoyage et transformation du jeu de donn√©es pour permettre une mod√©lisation efficace.
""")

    # Conversion de la date
    atp['Date'] = pd.to_datetime(atp['Date'])
    atp['Year'] = atp['Date'].dt.year
    st.markdown("### üîÑ Conversion des types")
    st.dataframe(atp[['Date', 'Year']].head())

    st.markdown("### üîÑ Pourcentages de NA par colonne")
    # Calcul des pourcentages de NA par colonne
    manquants = atp.isna().mean() * 100
    manquants = manquants[manquants > 0]  # filtrer seulement colonnes avec NA > 0

    st.dataframe(manquants.sort_values(ascending=False))

    # Graphique barres des NA
    fig, ax = plt.subplots(figsize=(10,6))
    manquants.sort_values(ascending=False).plot(kind='bar', color='orange', ax=ax)
    ax.set_ylabel("Pourcentage de valeurs manquantes (%)")
    ax.set_title("Taux de valeurs manquantes par colonne")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()

    st.pyplot(fig)


    # Cr√©ation de la cible et inversion des joueurs
    st.markdown("### üéØ Cr√©ation de la variable cible `Target` avec inversion al√©atoire")
    create_target_with_random_inversion(atp, seed=42)
    st.dataframe(atp[['PlayerA', 'PlayerB', 'Target']].sample(5))

    # Distribution de Target
    st.write("**Distribution de la variable `Target` :**")
    st.bar_chart(atp['Target'].value_counts())

    # Feature engineering
    st.markdown("### üõ†Ô∏è Feature Engineering")
    atp['Rank_Diff'] = atp['RankA'] - atp['RankB']
    atp['Elo_Diff'] = atp['EloA'] - atp['EloB']
    st.dataframe(atp[['RankA', 'RankB', 'Rank_Diff', 'EloA', 'EloB', 'Elo_Diff']].head())

    # Visualisation des distributions
    st.markdown("### üìä Visualisation des nouvelles variables")

    fig1, ax1 = plt.subplots()
    sns.histplot(atp['Rank_Diff'], bins=50, kde=True, ax=ax1)
    ax1.set_title("Distribution de Rank_Diff")
    st.pyplot(fig1)

    fig2, ax2 = plt.subplots()
    sns.histplot(atp['Elo_Diff'], bins=50, kde=True, color='orange', ax=ax2)
    ax2.set_title("Distribution de Elo_Diff")
    st.pyplot(fig2)

#######Page 4
if page == pages[4]:
    st.title("Mod√©lisation")

    st.markdown("""
    Voici les performances des mod√®les sur le jeu de test, avec accuracy et matrices de confusion.
    """)

    # Chargement des donn√©es test (ajuste les chemins si besoin)
    X_test_final = pd.read_csv("X_test_final.csv")
    y_test = pd.read_csv("y_test.csv").values.ravel()

    # Chargement des mod√®les
    rf_model = joblib.load('rf_model.joblib')
    lr_model = joblib.load('lr_model.joblib')
    dtc_model = joblib.load('dtc_model.joblib')
    knn_model = joblib.load('knn_model.joblib')

    # Fonction pour afficher matrice de confusion
    def plot_confusion_matrix(y_true, y_pred, model_name):
        cm = confusion_matrix(y_true, y_pred)
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
        ax.set_xlabel('Pr√©dictions')
        ax.set_ylabel('Vraies √©tiquettes')
        ax.set_title(f'Matrice de confusion - {model_name}')
        st.pyplot(fig)

    # Menu d√©roulant pour choisir un mod√®le
    model_choice = st.selectbox(
        "S√©lectionnez un mod√®le √† afficher :",
        ("Random Forest", "R√©gression Logistique", "Decision Tree", "K-Nearest Neighbors")
    )

    # Dictionnaire des mod√®les et leurs pr√©dictions
    models = {
        "Random Forest": rf_model.predict(X_test_final),
        "R√©gression Logistique": lr_model.predict(X_test_final),
        "Decision Tree": dtc_model.predict(X_test_final),
        "K-Nearest Neighbors": knn_model.predict(X_test_final)
    }

    # Affichage des r√©sultats du mod√®le s√©lectionn√©
    preds = models[model_choice]
    acc = accuracy_score(y_test, preds)
    st.write(f"### {model_choice}")
    st.write(f"Accuracy : {acc:.3f}")
    plot_confusion_matrix(y_test, preds, model_choice)

        
#######Page 5
if page == pages[5]:
    st.title("üìà Application m√©tier et conclusion")

    st.markdown("""
## üéØ Application m√©tier

Dans le cadre de ce projet, nous avons con√ßu une strat√©gie de **paris sportifs** fond√©e sur l‚Äôidentification des *outsiders* ‚Äî c‚Äôest-√†-dire les √©quipes consid√©r√©es comme moins probables de gagner par les bookmakers ‚Äî et sur l'agr√©gation des pr√©dictions de plusieurs mod√®les de machine learning.

L‚Äôapplication m√©tier est double :
- Optimiser la prise de d√©cision en mati√®re de paris en se concentrant sur les **matchs √† forte valeur attendue**.
- Exploiter l‚Äôintelligence collective de mod√®les (**vote majoritaire**) pour maximiser la fiabilit√© des pr√©dictions, tout en prenant en compte les **cotes propos√©es** (via un filtre sur les cotes minimales).

### üß™ Deux strat√©gies simul√©es :
1. **Strat√©gie prudente** : parier uniquement lorsque **tous les mod√®les (4/4)** sont d'accord.
2. **Strat√©gie opportuniste** : parier d√®s que **3 mod√®les sur 4** sont d'accord et que la **cote ‚â• 2.5**, favorisant les gains plus √©lev√©s.

### üìÖ Donn√©es utilis√©es :
- **Jeu d'entra√Ænement** : saisons **2000 √† 2011**
- **Jeu de test** : saisons **2012 √† 2018**

Cette s√©paration temporelle respecte une logique de **pr√©vision r√©elle** (pas de data leakage), simulant un vrai usage m√©tier.
""")

    # Donn√©es sous forme de dictionnaire
    data = {
        "Jeu de donn√©es": ["Entra√Ænement", "Entra√Ænement", "Test", "Test"],
        "Confiance": ["100‚ÄØ% (4/4)", "75‚ÄØ% (3/4)", "100‚ÄØ% (4/4)", "75‚ÄØ% (3/4)"],
        "Cote min.": ["0", "‚â• 2.5", "0", "‚â• 2.5"],
        "Nombre de paris": [4573, 886, 2557, 745],
        "Mise (‚Ç¨)": [4573.00, 886.00, 2557.00, 745.00],
        "Gains (‚Ç¨)": [90.62, 2889.86, 1359.68, 3177.64],
        "ROI (%)": [1.98, 326.17, 53.17, 426.53],
        "% Outsiders corrects": ["29.79‚ÄØ%", "29.79‚ÄØ%", "26.95‚ÄØ%", "26.95‚ÄØ%"]
    }

    df_stats = pd.DataFrame(data)

    # Affichage Streamlit
    st.markdown("## üìä R√©sultats des performances")
    st.dataframe(df_stats)

    st.markdown("""
## ‚úÖ Conclusion

Ce projet d√©montre la possibilit√© de g√©n√©rer des retours sur investissement positifs en exploitant l‚Äô**intelligence collective de mod√®les pr√©dictifs** et des filtres strat√©giques sur les cotes.

La m√©thode respecte la rigueur d‚Äôun **sc√©nario m√©tier r√©aliste**, sans fuite d‚Äôinformations, et montre un fort potentiel d'application dans l‚Äôaide √† la d√©cision pour les parieurs.

""")
if page == pages[6]:
    st.title("üß≠ Critique et perspectives")

    st.markdown("""
## ‚ùóÔ∏è6.6 Limites du projet

M√™me si les r√©sultats sont prometteurs, plusieurs **limites** doivent √™tre soulign√©es :

- **S√©lection manuelle des features** : le projet repose sur des variables simples (classements, ELO, etc.). D'autres dimensions (surface, fatigue, historiques H2H, m√©t√©o, etc.) n'ont pas √©t√© int√©gr√©es.
- **Pas de tuning hyperparam√®tres** approfondi : les mod√®les ont √©t√© entra√Æn√©s avec des param√®tres par d√©faut ou une grille limit√©e. Une optimisation plus pouss√©e aurait pu am√©liorer les scores.
- **Absence de validation crois√©e temporelle** : le d√©coupage temporel est r√©aliste, mais ne couvre qu‚Äôun seul split train/test. Une validation crois√©e glissante aurait permis de mieux mesurer la robustesse.
- **Mod√®les statiques** : les mod√®les ne sont pas recalibr√©s saison apr√®s saison, ce qui r√©duit leur capacit√© √† s‚Äôadapter √† des √©volutions r√©centes dans le sport.

""")

    st.markdown("""
## üå± 6.7 Perspectives d‚Äôam√©lioration

Avec plus de temps, plusieurs axes d'am√©lioration sont envisageables :

- **Feature engineering avanc√©** :
  - Ajout de variables contextuelles : surface, m√©t√©o, blessure, historique de confrontation, fatigue (nombre de sets/matchs r√©cents).
  - Int√©gration de cotes plus pr√©cises (ouverture, live) pour mieux quantifier la "valeur".
  - Calcul de tendances ou dynamiques r√©centes (forme glissante sur les 5 derniers matchs, par exemple).

- **Mod√®les plus puissants** :
  - Test de mod√®les avanc√©s comme XGBoost, LightGBM, CatBoost ou m√™me des r√©seaux de neurones tabulaires.
  - Exploration de mod√®les probabilistes pour estimer des distributions plut√¥t que des classes binaires.

- **Validation plus rigoureuse** :
  - Mise en place d‚Äôune **validation crois√©e temporelle glissante** pour simuler plusieurs ann√©es de paris en continu.
  - Backtesting plus complet avec gestion dynamique du capital et simulations de mises variables.

- **Application m√©tier automatis√©e** :
  - D√©veloppement d‚Äôune interface compl√®te pour le suivi en temps r√©el des matchs √† parier.
  - D√©ploiement sur API ou application mobile pour alerter les utilisateurs en temps r√©el.
  - Int√©gration avec des plateformes de paris pour automatiser les d√©cisions.

""")

    st.markdown("""
## üîÑ En r√©sum√©

Ce projet pose les **fondations solides** d'une strat√©gie de paris bas√©e sur la donn√©e, mais **de nombreuses am√©liorations restent possibles** pour passer √† l‚Äô√©chelle.  
Avec plus de temps, on pourrait aller vers une **solution automatis√©e, dynamique et intelligente**, capable de d√©tecter des paris √† forte valeur en continu.
""")
